{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ckiptagger import WS, POS\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('news_clustering_train.tsv', sep='\\t')\n",
    "train_titles = {row['index']: row['title'] for _, row in df_train.iterrows()}\n",
    "train_classes = {row['index']: row['class'] for _, row in df_train.iterrows()}\n",
    "\n",
    "df_test = pd.read_csv('news_clustering_test.tsv', sep='\\t')\n",
    "test_titles = {row['index']: row['title'] for _, row in df_test.iterrows()}\n",
    "test_classes = {row['index']: row['class'] for _, row in df_test.iterrows()}\n",
    "\n",
    "all_news_class = ['體育', '財經', '科技', '旅遊', '農業', '遊戲']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 斷詞 + POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 忽略警告\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "ws, pos = WS('./data/'), POS('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3280d3f8eb40488fb05a404435ebadf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1800.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_title_cuts = {}\n",
    "for index, title in tqdm(train_titles.items()):\n",
    "    word_s = ws([title])\n",
    "    word_p = pos(word_s)\n",
    "    train_title_cuts[index] = list(zip(word_s[0], word_p[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_title_cuts = {}\n",
    "for index, title in tqdm(test_titles.items()):\n",
    "    word_s = ws([title])\n",
    "    word_p = pos(word_s)\n",
    "    test_title_cuts[index] = list(zip(word_s[0], word_p[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "index2word = {}\n",
    "unique_words = list(set(word for pairs in train_title_cuts.values() for word, _ in pairs))\n",
    "\n",
    "for index, word in enumerate(unique_words):\n",
    "    word2index[word] = index\n",
    "    index2word[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_vector_with_selection(pairs, word2index):\n",
    "    excluded_flags = [\n",
    "        'Nh', 'Nep', 'Nes', 'DE', 'T', 'P', 'V_2', 'SHI',\n",
    "        'Dfa', 'Dfb', 'Da', 'Di', 'Dk',\n",
    "        'Caa', 'Cab', 'Cba', 'Cbb',\n",
    "        'COLONCATEGORY', 'COMMACATEGORY', 'DASHCATEGORY', 'DOTCATEGORY', 'ETCCATEGORY', 'EXCLAMATIONCATEGORY',\n",
    "        'PARENTHESISCATEGORY', 'PAUSECATEGORY', 'PERIODCATEGORY', 'QUESTIONCATEGORY', 'SEMICOLONCATEGORY',\n",
    "        'SPCHANGECATEGORY', 'WHITESPACE'\n",
    "    ]\n",
    "    vector = np.zeros(len(word2index))\n",
    "    for word, flag in pairs:\n",
    "        if word in word2index and flag not in excluded_flags:\n",
    "            vector[word2index[word]] += 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bow_vectors = {\n",
    "    index: get_bow_vector_with_selection(pairs, word2index)\n",
    "    for index, pairs in train_title_cuts.items()\n",
    "}\n",
    "\n",
    "test_bow_vectors = {\n",
    "    index: get_bow_vector_with_selection(pairs, word2index)\n",
    "    for index, pairs in test_title_cuts.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "train_index_array, train_vector_array = list(zip(*train_bow_vectors.items()))\n",
    "\n",
    "# 使用`TfidfTransformer`來將`train_vector_array`轉換成`train_tfidf_vector_array`\n",
    "tfidfer = TfidfTransformer()\n",
    "train_tfidf_vector_array = tfidfer.fit_transform(train_vector_array)\n",
    "\n",
    "display(train_tfidf_vector_array,\n",
    "        type(train_tfidf_vector_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_vectors = {}\n",
    "\n",
    "for i, index in enumerate(train_index_array):\n",
    "    vector = train_tfidf_vector_array.getrow(i).toarray()[0]\n",
    "    train_tfidf_vectors[index] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_tfidf_vectors[120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index_array, test_vector_array = list(zip(*test_bow_vectors.items()))\n",
    "\n",
    "# 使用同一個`TfidfTransformer`來轉換testing dataset\n",
    "test_tfidf_vector_array = tfidfer.transform(test_vector_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf_vectors = {}\n",
    "\n",
    "for i, index in enumerate(test_index_array):\n",
    "    vector = test_tfidf_vector_array.getrow(i).toarray()\n",
    "    test_tfidf_vectors[index] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF + Group mean vector: 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_vectors = {news_class: [] for news_class in all_news_class}\n",
    "group_mean_vector = {}\n",
    "\n",
    "for index, vector in sorted(train_tfidf_vectors.items()):\n",
    "    news_class = train_classes[index]\n",
    "    group_vectors[news_class].append(vector)\n",
    "\n",
    "for news_class, vectors in group_vectors.items():\n",
    "    group_mean_vector[news_class] = np.mean(vectors, axis=0)\n",
    "\n",
    "display(group_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(bow1, bow2):\n",
    "    uni_dist = lambda x: x/(np.sqrt(np.sum(x**2)))\n",
    "    return np.sum(uni_dist(bow1) * uni_dist(bow2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = {news_class: [] for news_class in all_news_class}\n",
    "\n",
    "for index, vector in sorted(test_tfidf_vectors.items()):\n",
    "    if np.sum(np.square(vector)) == 0:\n",
    "        continue\n",
    "\n",
    "    max_val = -2.0\n",
    "    max_class = None\n",
    "    \n",
    "    for news_class, ref_vector in group_mean_vector.items():\n",
    "        val = cosine_similarity(ref_vector, vector)\n",
    "        if val > max_val:\n",
    "            max_class = news_class\n",
    "            max_val = val\n",
    "\n",
    "    classification[max_class].append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "accuracy=[]\n",
    "\n",
    "for group, ids in classification.items():\n",
    "    counter = Counter([test_classes[id] for id in ids])\n",
    "    prediciton=round(counter[group]/sum(counter.values())*100,2)\n",
    "    accuracy.append(prediciton)\n",
    "    print(f'{group} : {str(counter):70} \\taccuracy : {prediciton}%')\n",
    "\n",
    "print(f'\\nAverage accuracy : {round(np.mean(accuracy),2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, svd_solver='full')\n",
    "anchor_classes, anchor_vectors = list(zip(*group_mean_vector.items()))\n",
    "\n",
    "# 為了看清楚Group Mean Vector怎麼幫助我們做分類問題，我們針對Group Mean Vector (anchor) 來進行PCA降維\n",
    "reduced_anchor_vectors = pca.fit_transform(anchor_vectors)\n",
    "reduced_test_tfidf_vector_array = pca.transform(test_tfidf_vector_array.toarray())\n",
    "\n",
    "display(reduced_test_tfidf_vector_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_class_array = np.vectorize(test_classes.get)(test_index_array)\n",
    "\n",
    "label_mapping = {\n",
    "    '體育': 'sport',\n",
    "    '財經': 'financial',\n",
    "    '科技': 'tech',\n",
    "    '旅遊': 'travel',\n",
    "    '農業': 'agriculture',\n",
    "    '遊戲': 'game'\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for real_class in all_news_class:\n",
    "    plt.scatter(reduced_test_tfidf_vector_array[test_class_array == real_class, 0],\n",
    "                reduced_test_tfidf_vector_array[test_class_array == real_class, 1],\n",
    "                label=label_mapping[real_class],\n",
    "                alpha=0.3)\n",
    "    i = anchor_classes.index(real_class)\n",
    "    plt.plot([0, reduced_anchor_vectors[i, 0]], [0, reduced_anchor_vectors[i, 1]])\n",
    "plt.legend(loc=\"best\", shadow=False, scatterpoints=1)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
